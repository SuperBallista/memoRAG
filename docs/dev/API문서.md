# memoRAG API ë¬¸ì„œ

Python ì½”ë“œì—ì„œ memoRAGë¥¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

## ì„¤ì¹˜

```bash
pip install -e .
```

---

## ë¹ ë¥¸ ì‹œì‘

```python
from pathlib import Path
from src.core import DocumentParser, EmbeddingEngine, VectorSearch
from src.services import IndexingService, QueryService

# 1. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
parser = DocumentParser(chunk_size=512, chunk_overlap=50)
embedder = EmbeddingEngine(
    model_name="paraphrase-multilingual-MiniLM-L12-v2",
    device="cpu"
)
vector_db = VectorSearch(
    persist_directory="./my_chroma",
    collection_name="my_docs"
)

# 2. ì¸ë±ì‹±
indexing_service = IndexingService(parser, embedder, vector_db)
stats = indexing_service.index_folder(
    folder_path=Path("./documents"),
    show_progress=True
)
print(f"ì¸ë±ì‹± ì™„ë£Œ: {stats['total_chunks']}ê°œ ì²­í¬")

# 3. ê²€ìƒ‰
query_service = QueryService(embedder, vector_db, top_k=5)
results = query_service.search("ì°¾ê³ ì‹¶ì€ ë‚´ìš©")

for result in results:
    print(f"{result.metadata['file_name']}: {result.score:.3f}")
    print(result.snippet)
```

---

## Core API

### DocumentParser

ë¬¸ì„œ íŒŒì‹± í´ë˜ìŠ¤

#### ì´ˆê¸°í™”

```python
parser = DocumentParser(
    chunk_size=512,        # ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)
    chunk_overlap=50       # ì²­í¬ ì¤‘ë³µ (ë¬¸ì ìˆ˜)
)
```

#### ë©”ì„œë“œ

**parse(file_path: Path) -> List[DocumentChunk]**

íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

```python
from pathlib import Path

chunks = parser.parse(Path("document.pdf"))

for chunk in chunks:
    print(chunk.text)           # í…ìŠ¤íŠ¸ ë‚´ìš©
    print(chunk.metadata)       # ë©”íƒ€ë°ì´í„°
    print(chunk.page)           # í˜ì´ì§€ ë²ˆí˜¸
```

**is_supported(file_path: Path) -> bool**

ì§€ì› í˜•ì‹ í™•ì¸

```python
if DocumentParser.is_supported(Path("file.pdf")):
    chunks = parser.parse(Path("file.pdf"))
```

#### DocumentChunk

```python
@dataclass
class DocumentChunk:
    text: str                    # í…ìŠ¤íŠ¸ ë‚´ìš©
    metadata: Dict[str, any]     # ë©”íƒ€ë°ì´í„°
    page: Optional[int]          # í˜ì´ì§€/ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸
    section: Optional[str]       # ì„¹ì…˜/ì‹œíŠ¸ ì´ë¦„
```

---

### EmbeddingEngine

ì„ë² ë”© ì—”ì§„ í´ë˜ìŠ¤

#### ì´ˆê¸°í™”

```python
embedder = EmbeddingEngine(
    model_name="paraphrase-multilingual-MiniLM-L12-v2",
    device="cpu",           # or "cuda"
    batch_size=32
)
```

#### ë©”ì„œë“œ

**embed_documents(texts: List[str]) -> List[List[float]]**

ë¬¸ì„œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜

```python
texts = ["ë¬¸ì„œ 1", "ë¬¸ì„œ 2", "ë¬¸ì„œ 3"]
embeddings = embedder.embed_documents(texts)
# [[0.1, 0.2, ...], [0.3, 0.4, ...], ...]
```

**embed_query(text: str) -> List[float]**

ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜

```python
query_vector = embedder.embed_query("ê²€ìƒ‰ì–´")
# [0.1, 0.2, 0.3, ...]
```

**get_dimension() -> int**

ì„ë² ë”© ì°¨ì› ë°˜í™˜

```python
dim = embedder.get_dimension()  # 384 ë˜ëŠ” 768
```

---

### VectorSearch

ë²¡í„° ê²€ìƒ‰ ì—”ì§„ í´ë˜ìŠ¤

#### ì´ˆê¸°í™”

```python
vector_db = VectorSearch(
    persist_directory="./chroma",
    collection_name="default"
)
```

#### ë©”ì„œë“œ

**get_or_create_collection(collection_name: str)**

ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±

```python
collection = vector_db.get_or_create_collection("my_collection")
```

**add_documents(ids, embeddings, documents, metadatas)**

ë¬¸ì„œ ì¶”ê°€

```python
vector_db.add_documents(
    ids=["doc1", "doc2"],
    embeddings=[[0.1, 0.2, ...], [0.3, 0.4, ...]],
    documents=["í…ìŠ¤íŠ¸ 1", "í…ìŠ¤íŠ¸ 2"],
    metadatas=[{"file": "a.txt"}, {"file": "b.txt"}]
)
```

**search(query_embedding, top_k, where) -> Dict**

ë²¡í„° ê²€ìƒ‰

```python
results = vector_db.search(
    query_embedding=[0.1, 0.2, ...],
    top_k=5,
    where={"file_type": "pdf"}  # í•„í„° (ì„ íƒ)
)
```

**delete_collection(collection_name: str)**

ì»¬ë ‰ì…˜ ì‚­ì œ

```python
vector_db.delete_collection("old_collection")
```

**list_collections() -> List[str]**

ëª¨ë“  ì»¬ë ‰ì…˜ ì´ë¦„ ë°˜í™˜

```python
collections = vector_db.list_collections()
# ["collection1", "collection2", ...]
```

---

## Services API

### IndexingService

ì¸ë±ì‹± ì„œë¹„ìŠ¤

#### ì´ˆê¸°í™”

```python
from src.services import IndexingService

indexing_service = IndexingService(parser, embedder, vector_db)
```

#### ë©”ì„œë“œ

**index_folder(folder_path, collection_name, recursive, show_progress) -> dict**

í´ë” ì¸ë±ì‹±

```python
stats = indexing_service.index_folder(
    folder_path=Path("./documents"),
    collection_name="my_docs",
    recursive=True,
    show_progress=True
)

print(stats)
# {
#     "total_files": 10,
#     "total_chunks": 50,
#     "errors": 0,
#     "error_files": []
# }
```

**index_file(file_path, collection_name) -> int**

ë‹¨ì¼ íŒŒì¼ ì¸ë±ì‹±

```python
count = indexing_service.index_file(
    file_path=Path("document.pdf"),
    collection_name="my_docs"
)
print(f"{count}ê°œ ì²­í¬ ìƒì„±")
```

---

### QueryService

ì¿¼ë¦¬ ì„œë¹„ìŠ¤

#### ì´ˆê¸°í™”

```python
from src.services import QueryService

query_service = QueryService(
    embedder=embedder,
    vector_db=vector_db,
    top_k=5,
    snippet_length=200
)
```

#### ë©”ì„œë“œ

**search(query, collection_name, top_k, filters) -> List[QueryResult]**

ìì—°ì–´ ê²€ìƒ‰

```python
results = query_service.search(
    query="ì²´ìœ¡ëŒ€íšŒ ì¤€ë¹„ë¬¼",
    collection_name="my_docs",
    top_k=5,
    filters={"file_type": "pdf"}  # ì„ íƒ
)

for result in results:
    print(f"íŒŒì¼: {result.metadata['file_name']}")
    print(f"ì ìˆ˜: {result.score}")
    print(f"ë‚´ìš©: {result.snippet}")
```

**format_results(results, show_score, show_snippet) -> str**

ê²°ê³¼ í¬ë§·íŒ…

```python
formatted = query_service.format_results(
    results=results,
    show_score=True,
    show_snippet=True
)
print(formatted)
```

#### QueryResult

```python
class QueryResult:
    text: str               # ì›ë³¸ í…ìŠ¤íŠ¸
    metadata: Dict          # ë©”íƒ€ë°ì´í„°
    score: float            # ìœ ì‚¬ë„ ì ìˆ˜ (0~1)
    snippet: str            # ì§§ì€ ë¯¸ë¦¬ë³´ê¸°
```

---

### ManagementService

ê´€ë¦¬ ì„œë¹„ìŠ¤

#### ì´ˆê¸°í™”

```python
from src.services import ManagementService

management_service = ManagementService(vector_db)
```

#### ë©”ì„œë“œ

**list_collections() -> List[str]**

ì»¬ë ‰ì…˜ ëª©ë¡

```python
collections = management_service.list_collections()
```

**get_collection_info(collection_name) -> Dict**

ì»¬ë ‰ì…˜ ì •ë³´

```python
info = management_service.get_collection_info("my_docs")
print(info['document_count'])
```

**delete_collection(collection_name) -> bool**

ì»¬ë ‰ì…˜ ì‚­ì œ

```python
success = management_service.delete_collection("old_docs")
```

**get_storage_size() -> int**

ì €ì¥ì†Œ í¬ê¸° (ë°”ì´íŠ¸)

```python
size = management_service.get_storage_size()
size_str = management_service.format_storage_size(size)
print(f"í¬ê¸°: {size_str}")
```

---

## Utils API

### Config

ì„¤ì • ê´€ë¦¬

```python
from src.utils import Config

# ì„¤ì • ë¡œë“œ
config = Config(Path("config.yaml"))

# ê°’ ê°€ì ¸ì˜¤ê¸°
model = config.get("embedding.model_name")
top_k = config.get("search.top_k", default=5)

# ê°’ ì„¤ì •
config.set("search.top_k", 10)

# ì €ì¥
config.save(Path("config.yaml"))
```

### Logger

ë¡œê¹… ì„¤ì •

```python
from src.utils import setup_logger

logger = setup_logger(
    name="my_app",
    level="INFO",
    log_file=Path("./logs/app.log"),
    use_rich=True
)

logger.info("ì •ë³´ ë©”ì‹œì§€")
logger.error("ì˜¤ë¥˜ ë©”ì‹œì§€")
```

---

## ê³ ê¸‰ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸

```python
from pathlib import Path
from src.core import DocumentParser, EmbeddingEngine, VectorSearch

def custom_pipeline(folder: Path, query: str):
    """ì»¤ìŠ¤í…€ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸"""
    
    # ì´ˆê¸°í™”
    parser = DocumentParser()
    embedder = EmbeddingEngine()
    vector_db = VectorSearch()
    
    # íŒŒì¼ íŒŒì‹±
    all_chunks = []
    for file_path in folder.glob("*.pdf"):
        chunks = parser.parse(file_path)
        all_chunks.extend(chunks)
    
    # ì„ë² ë”© & ì €ì¥
    texts = [c.text for c in all_chunks]
    embeddings = embedder.embed_documents(texts)
    
    vector_db.add_documents(
        ids=[f"chunk_{i}" for i in range(len(texts))],
        embeddings=embeddings,
        documents=texts,
        metadatas=[c.metadata for c in all_chunks]
    )
    
    # ê²€ìƒ‰
    query_vector = embedder.embed_query(query)
    results = vector_db.search(query_vector, top_k=3)
    
    return results
```

### ì˜ˆì‹œ 2: ë°°ì¹˜ ì¸ë±ì‹±

```python
def batch_index_multiple_folders(folders: List[Path]):
    """ì—¬ëŸ¬ í´ë”ë¥¼ ë°°ì¹˜ ì¸ë±ì‹±"""
    
    # ê³µí†µ ì»´í¬ë„ŒíŠ¸
    parser = DocumentParser()
    embedder = EmbeddingEngine()
    
    for folder in folders:
        # í´ë”ë³„ë¡œ ë³„ë„ ì»¬ë ‰ì…˜ ìƒì„±
        collection_name = folder.name
        vector_db = VectorSearch(collection_name=collection_name)
        
        indexing_service = IndexingService(parser, embedder, vector_db)
        stats = indexing_service.index_folder(folder)
        
        print(f"{collection_name}: {stats['total_chunks']}ê°œ ì²­í¬")
```

### ì˜ˆì‹œ 3: í†µí•© ê²€ìƒ‰ (ì—¬ëŸ¬ ì»¬ë ‰ì…˜)

```python
def search_all_collections(query: str) -> List[QueryResult]:
    """ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰"""
    
    embedder = EmbeddingEngine()
    vector_db = VectorSearch()
    
    all_results = []
    
    for collection in vector_db.list_collections():
        query_service = QueryService(embedder, vector_db, top_k=3)
        results = query_service.search(query, collection_name=collection)
        all_results.extend(results)
    
    # ì ìˆ˜ìˆœ ì •ë ¬
    all_results.sort(key=lambda r: r.score, reverse=True)
    
    return all_results[:10]  # ìƒìœ„ 10ê°œ
```

---

## íƒ€ì… íŒíŠ¸

ëª¨ë“  APIëŠ” íƒ€ì… íŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

```python
from typing import List, Dict, Optional
from pathlib import Path

def my_function(
    file_path: Path,
    options: Optional[Dict] = None
) -> List[str]:
    """íƒ€ì…ì´ ëª…í™•í•œ í•¨ìˆ˜"""
    pass
```

---

## ì—ëŸ¬ ì²˜ë¦¬

### ì¼ë°˜ì ì¸ ì˜ˆì™¸

```python
from src.core import DocumentParser

try:
    chunks = parser.parse(Path("file.pdf"))
except FileNotFoundError:
    print("íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
except ValueError as e:
    print(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {e}")
except ImportError as e:
    print(f"ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”: {e}")
```

### ê¶Œì¥ íŒ¨í„´

```python
import logging

logger = logging.getLogger(__name__)

try:
    result = process_document(file_path)
except Exception as e:
    logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    raise  # ë˜ëŠ” ì ì ˆíˆ ì²˜ë¦¬
```

---

## ì„±ëŠ¥ ìµœì í™”

### ë°°ì¹˜ ì²˜ë¦¬

```python
# ë‚˜ìœ ì˜ˆ: í•˜ë‚˜ì”© ì²˜ë¦¬
for text in texts:
    embedding = embedder.embed_documents([text])

# ì¢‹ì€ ì˜ˆ: ë°°ì¹˜ ì²˜ë¦¬
embeddings = embedder.embed_documents(texts)
```

### ì¬ì‚¬ìš©

```python
# ë‚˜ìœ ì˜ˆ: ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±
for query in queries:
    embedder = EmbeddingEngine()  # ëŠë¦¼!
    result = embedder.embed_query(query)

# ì¢‹ì€ ì˜ˆ: í•œ ë²ˆë§Œ ìƒì„±
embedder = EmbeddingEngine()
for query in queries:
    result = embedder.embed_query(query)
```

---

## ì°¸ê³ 

ë” ë§ì€ ì˜ˆì‹œëŠ” ë‹¤ìŒ íŒŒì¼ ì°¸ê³ :

- `src/cli/main.py` - CLI êµ¬í˜„ ì˜ˆì‹œ
- `test_simple.py` - í†µí•© í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
- `tests/test_*.py` - ìœ ë‹› í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

---

**Happy Coding!** ğŸš€

